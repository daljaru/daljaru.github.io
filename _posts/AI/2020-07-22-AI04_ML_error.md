---
layout: post
title: "Error, Overfitting, Underfitting"
date: 2020-07-22
desc: "Error, Overfitting, Underfitting"
keywords: overfitting, underfitting
categories: [AI]
tags: [overfitting, underfitting]
---

## Error

___

1. Training error(학습 오차)

    라벨이 붙어있지만 모든 데이터를 다 perfect하게 맞추는 모델은 아닙니다.

2. Test error(예측 오차)

    신규 데이터를 넣어서 결과를 예측했을 때의 오차입니다. 
    예측 오차는 작을수록 좋은 모델이 완성된 것입니다.

<br>

## Overfitting, Underfitting

___

Training Error가 높으면 높을 수록 좋지 않습니다. 이 경우는 Underfitting되었다고 표현합니다. 

반대로 Training Error가 작으면 작을 수록 좋습니다. 하지만 예외적으로 만약 training error가 극단적으로 작다면 모델의 성능을 의심해봐야 합니다. training data에만 정확한 모델이 만들어졌을 가능성이 높기 때문입니다. 

만약에 training Error가 극단적으로 낮은데 신규 데이터의 에러(test Error)가 높게 나온다면 과도하게 train data에 의존한 모델이 만들어진 것입니다. 이 경우를 Overfitting 되었다고 표현합니다. 

<br>

Underfitting의 경우에는 해결책으로 학습데이터의 양을 늘리거나 학습의 기간을 늘립니다. 

Overfitting의 경우에는 해결책으로 학습데이터가 너무 천편일률적이지는 않은지 확인하는 것이 좋습니다. 학습데이터의 다양성을 늘리는 것이 중요하고 또는 데이터의 학습 깊이를 낮추는 것이 좋습니다. 굉장히 
세밀하게, 오차를 허용하지 않게 학습이 되었을 가능성이 높기 때문입니다. 

<br>

## 라벨의 개수

___

라벨(데이터셋의 정답에 해당하는 데이터 클래스)은 최대 50개가 마지노선입니다. 만약 50개가 넘는다면 굉장한 수준의 컴퓨팅 파워가 필요하기 때문에 데이터 셋을 변형하는 과정에서 조절해야 합니다.  